{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvNV5AKGQ8TF"
   },
   "source": [
    "# DP-CGAN Notebook\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook provides the PyTorch implementation of conditional GAN trained in a differentially private setting. This method was firstly introduced in **DP-CGAN : Differentially Private Synthetic Data and Label\n",
    "Generation** (https://arxiv.org/abs/2001.09700). Originally the model was used for training a differentially-private (DP) generative model on images. However, in this notebook, we look into the application of DP-CGAN on tabular data. The details of this notebook, such as model architecture and preprocessing steps, can be customized further to align with different use cases. \n",
    "\n",
    "\n",
    "This notebook will explore the [Kaggle Credit Fraud Detection Dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) but includes others too. This dataset contains 29 continuous features, with ~285,000 examples/rows and binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z89SUFgKO8bX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from opacus import PrivacyEngine\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bHIz6MHqUl2"
   },
   "source": [
    "## Differential Privacy\n",
    "\n",
    "A brief introduction on differential privacy has been provided in the PATE-GAN notebook, which is as follows:\n",
    "\n",
    "\n",
    "Getting the import logistics out of the way, we'll go into the depths of the PATE-GAN model. The deep math will be deferred back to the paper, and I will try to include only the important bits. \n",
    "\n",
    "First things first, an introduction to the idea of **Differential Privacy (DP)**. DP describes the effect on a model's output prediction if a single example is removed from the training dataset. Each specific training example should have very little sway on model behaviour. Intuitively: to maximize privacy, the model should not memorize individual examples, but learn something about the dataset as a whole. \n",
    "\n",
    "To quantify DP, models are typically trained to be **(ϵ, δ)-Differentially Private**. Ie. the removal of any one example will affect the models regular output by, at most, exp(ϵ) * output + δ. \n",
    "\n",
    "Though this canonical explanation of DP is typically applied to one model, we need our entire GAN model to be differentially-private. However, it can be proven that so long as the discriminator is differentially-private, then the generator is also differentially-private. This result is derived from the post-processing theorem. It states that the composition of some function f with some (ϵ, δ)-DP function g, still results in a (ϵ, δ)-DP function. Intuitively, if you are given some (ϵ, δ)-DP model G, then no amount of clever tinkering can make the model less differentially private. This has a link to information processing, where you cannot create more information then already exists in a vacuum. \n",
    "\n",
    "This is all well and great, but what does this mean for application? Can't we just delete columns with names/ids? This may seem attracive, but this is an extremely weak attempt at maintaining privacy of dataset members. The rows of the exposed dataset can be used to search up public records, and in-turn, recover the deleted names/ids. DP denies this kind of attack by minimizing the effect of single members, making linkage attacks untractable. \n",
    "\n",
    "We try to give intuitions behind DP, but if you're only convinced by math we have some excellent resources. There's a good write-up on the theory and math behind DP here: https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mshxti0dsgVv"
   },
   "source": [
    "## Differential Privacy with PyTorch\n",
    "\n",
    "The same notion of differential privacy described above applies to DP-CGAN. In this notebook, we provide a PyTorch implementation of DP-CGAN where the differential privacy is conducted using the Opacus library (https://opacus.ai/). Opacus adds privacy-related responsibilities to the main PyTorch training objects, i.e., model, optimizer, and the data loader where:\n",
    "- Model is wrapped to also compute per sample gradients.\n",
    "- Optimizer is now responsible for gradient clipping and adding noise to the gradients.\n",
    "- DataLoader is updated to perform Poisson sampling.\n",
    "\n",
    "All this can be done by \n",
    "1. Instantiating the PrivacyEngine\n",
    "\n",
    "  ```\n",
    "  privacy_engine = PrivacyEngine()\n",
    "  ```\n",
    "  \n",
    "2. Getting the private counterparts of the training objects while setting the values for the privacy budget, i.e., ϵ and δ. \n",
    "  ``` \n",
    "  model, optimizer, data_loader = \n",
    "  privacy_engine.make_private_with_epsilon(\n",
    "                          module,\n",
    "                          optimizer,\n",
    "                          data_loader,\n",
    "                          max_grad_norm,\n",
    "                          target_epsilon,\n",
    "                          target_delta,\n",
    "                          epochs\n",
    "                        )\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ca4jMS-bv6m"
   },
   "source": [
    "## CGAN\n",
    "\n",
    "Rather than using a vanilla GAN model to generate synthetic data, we employ conditional GAN to be able to have control over the labels of the generated samples. This conditioning can be done by concatenating the label data with the input noise of the Generator. Similarly, the Discriminator takes the concatenation of the data samples and the labels as the input.\n",
    "Generator and Discriminator in our CGAN architecture include a 2-layer MLP with ReLU nonlinearity. The Generator outputs the generated samples by applying Tanh, while the Discriminator predicts the fakeness of its input by outputting a sigmoid.\n",
    "Before starting the training, Normal Xavier initialization is applied to the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mmYm3eoXea44"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Conditional GAN generator\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, latent_dim: int, ngf: int, labels_dim: int, features_dim: int\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            latent_dim (int): The size of the input noise.\n",
    "            ngf (int): The size of the features is the generator layers.\n",
    "            label_dim (int): The size of the label vector for each sample.\n",
    "            features_dim (int): The number of the data features based on the dataset.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.labels_dim = labels_dim\n",
    "        self.features_dim = features_dim\n",
    "        self.ngf = ngf\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim + self.labels_dim, self.ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(ngf, features_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, noise: torch.Tensor, labels: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        if self.labels_dim > 1:\n",
    "            labels = F.one_hot(labels, num_classes=self.labels_dim)\n",
    "        else:\n",
    "            labels = torch.unsqueeze(labels, -1)\n",
    "        g_input = torch.cat((noise, labels), -1)\n",
    "        x = self.model(g_input)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Conditional GAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, ndf: int, features_dim: int, labels_dim: int) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ndf (int): The size of the features is the discriminator layers.\n",
    "            features_dim (int): The number of the data features based on the dataset.\n",
    "            labels_dim (int): The size of the label vector for each sample\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.labels_dim = labels_dim\n",
    "        self.features_dim = features_dim\n",
    "        self.ndf = ndf\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.features_dim + self.labels_dim, self.ndf),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(ndf, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, input: torch.Tensor, labels: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        if self.labels_dim > 1:\n",
    "            labels = F.one_hot(labels, num_classes=self.labels_dim)\n",
    "        else:\n",
    "            labels = torch.unsqueeze(labels, -1)\n",
    "        input = input.view(input.size(0), -1)\n",
    "        d_input = torch.cat((input, labels), -1)\n",
    "        x = self.model(d_input)\n",
    "        return x\n",
    "\n",
    "\n",
    "def init_weights(m: nn.modules) -> None:\n",
    "    \"\"\"Initialize weights with Xavier normal initializer\n",
    "\n",
    "    Args:\n",
    "        m: Network module\n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal(m.weight)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaTwIw6FfHBj"
   },
   "source": [
    "## Datasets\n",
    "\n",
    "In this demo, we consider four tabular datasets with binary labels.\n",
    "Credit fraud detection\n",
    "UCI\n",
    "Cervical cancer\n",
    "Adult Census\n",
    "Note that the model performance and the spent privacy budget depend on the datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr1NFHxO7YcX"
   },
   "source": [
    "### Data Loaders\n",
    "\n",
    "We provide the data loaders for each dataset below. Feel free to add your customized data loader function to run the model using a dataset of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DmXX7gZmfMm0"
   },
   "outputs": [],
   "source": [
    "def load_credit_dataset(dset_dir: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads the credit dataset\n",
    "    Args:\n",
    "        dset_dir (str): Dataset directory\n",
    "    Returns:\n",
    "        A tuple containing the features and labels\n",
    "    \"\"\"\n",
    "    # if not os.path.isdir(dset_dir):\n",
    "    #     raise Exception(\"Dataset source file not found\")\n",
    "\n",
    "    dset_path = Path(dset_dir) / \"creditcard_fraud_detection.csv\"\n",
    "\n",
    "    df = pd.read_csv(dset_path)\n",
    "    features = df.copy()\n",
    "\n",
    "    labels = features.pop(\"Class\")\n",
    "    features = features.drop([\"rownames\", \"Time\"], axis=1)\n",
    "\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def load_uci_dataset(dset_dir: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads the UCI dataset\n",
    "    Note:\n",
    "        Amalgamates both test and train splits\n",
    "    Args:\n",
    "        dset_dir (str): Dataset directory\n",
    "    Returns:\n",
    "        A tuple containing the features and labels\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(dset_dir):\n",
    "        raise Exception(\"Dataset source directory not found\")\n",
    "\n",
    "    train_path = Path(dset_dir) / \"isolet1+2+3+4.data\"\n",
    "    test_path = Path(dset_dir) / \"isolet5.data\"\n",
    "\n",
    "    if not os.path.isfile(train_path):\n",
    "        raise Exception(\"Missing UCI training data\")\n",
    "\n",
    "    if not os.path.isfile(test_path):\n",
    "        raise Exception(\"Missing UCI test data\")\n",
    "\n",
    "    train_df = pd.read_csv(train_path, header=None)\n",
    "    test_df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "    train_features = np.array(train_df.loc[:, :616])\n",
    "    train_labels = np.array(train_df.loc[:, 617])\n",
    "\n",
    "    test_features = np.array(test_df.loc[:, :616])\n",
    "    test_labels = np.array(test_df.loc[:, 617])\n",
    "\n",
    "    vowels = np.array([1.0, 5.0, 9.0, 15.0, 21.0])\n",
    "\n",
    "    train_labels = np.isin(train_labels, vowels).astype(np.int32)\n",
    "    test_labels = np.isin(test_labels, vowels).astype(np.int32)\n",
    "\n",
    "    features = np.concatenate((train_features, test_features))\n",
    "    labels = np.concatenate((train_labels, test_labels))\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def load_cervical_cancer_dataset(\n",
    "    dset_dir: str,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads the cervical cancer dataset\n",
    "    Args:\n",
    "        dset_dir (str): Dataset directory\n",
    "    Returns:\n",
    "        A tuple containing the features and labels\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(dset_dir):\n",
    "        raise Exception(\"Dataset source directory not found\")\n",
    "\n",
    "    dset_path = Path(dset_dir) / \"kag_risk_factors_cervical_cancer.csv\"\n",
    "\n",
    "    dset_df = pd.read_csv(dset_path)\n",
    "    dset_df = dset_df.replace(\"?\", np.nan)\n",
    "\n",
    "    # There is an exceedingly large number of NaNs in these two columns\n",
    "    dset_df = dset_df.drop(\n",
    "        columns=[\n",
    "            \"STDs: Time since first diagnosis\",\n",
    "            \"STDs: Time since last diagnosis\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Drop the remaining NaNs\n",
    "    dset_df_no_nan = dset_df.dropna()\n",
    "\n",
    "    labels = np.array(dset_df_no_nan.pop(\"Biopsy\").astype(np.float32))\n",
    "    features = np.array(dset_df_no_nan.astype(np.float32))\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def load_adult_census_dataset(dset_dir: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads the adult census dataset\n",
    "    Note:\n",
    "        Amalgamates both test and train splits\n",
    "    Args:\n",
    "        dset_dir (str): Dataset directory\n",
    "    Returns:\n",
    "        A tuple containing the features and labels\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(dset_dir):\n",
    "        raise Exception(\"Dataset source directory not found\")\n",
    "\n",
    "    train_path = Path(dset_dir) / \"adult_processed_train.csv\"\n",
    "    test_path = Path(dset_dir) / \"adult_processed_test.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_labels = np.array(train_df.pop(\"income\"))\n",
    "    test_labels = np.array(test_df.pop(\"income\"))\n",
    "\n",
    "    train_features = np.array(train_df)\n",
    "    test_features = np.array(test_df)\n",
    "\n",
    "    features = np.concatenate((train_features, test_features))\n",
    "    labels = np.concatenate((train_labels, test_labels))\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def get_dataset_loader(\n",
    "    dset_src: str, dset_name: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Returns the specified dataset loader, according to dset_name\n",
    "    Args:\n",
    "        dset_src (str): Dataset source file/directory\n",
    "    Returns:\n",
    "        A tuple containing the features and labels\n",
    "    \"\"\"\n",
    "    if dset_name == \"credit_fraud\":\n",
    "        return load_credit_dataset(dset_src)\n",
    "    elif dset_name == \"UCI_ISOLET\":\n",
    "        return load_uci_dataset(dset_src)\n",
    "    elif dset_name == \"cervical_cancer\":\n",
    "        return load_cervical_cancer_dataset(dset_src)\n",
    "    elif dset_name == \"adult_census\":\n",
    "        return load_adult_census_dataset(dset_src)\n",
    "    else:\n",
    "        raise Exception(\"Can't find valid dataset loading function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfCP4Tkg6r-e"
   },
   "source": [
    "### Data Splitting\n",
    "\n",
    "Since the datasets we work with are likely to be unbalanced in terms of the labels, we employ stratified data splitting for train and test sets to retain the same distribution of classes among the labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7Ite2u5YfZ57"
   },
   "outputs": [],
   "source": [
    "def split_dataset(\n",
    "    test_ratio: float, dset_name: str, dset_src: str\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Splits the features and labels according to split_ratio\n",
    "\n",
    "    Args:\n",
    "        test_ratio (float): The ratio of test samples\n",
    "        dset_name (str): Dataset name\n",
    "        dset_src (str): Dataset source file\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the train and test features and labels\n",
    "    \"\"\"\n",
    "    features, labels = get_dataset_loader(dset_src, dset_name)\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        np.arange(len(labels)),\n",
    "        test_size=test_ratio,\n",
    "        shuffle=True,\n",
    "        stratify=labels,\n",
    "    )\n",
    "    train_features = features[train_idx]\n",
    "    train_labels = labels[train_idx]\n",
    "    test_features = features[test_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ors6uqgO9QmR"
   },
   "source": [
    "### Class Ratios\n",
    "\n",
    "When evaluating the model, we need to provide random noise and labels as the input of the Generator. To be attentive to the distribution of data classes in unbalanced datasets, we use the same class ratios for the synthetic dataset labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4XxR8_w-9Afi"
   },
   "outputs": [],
   "source": [
    "def class_ratios(labels: np.ndarray) -> Tuple[np.ndarray, list]:\n",
    "    \"\"\"Computes the class ratios for the synthetic dataset\n",
    "\n",
    "    Args:\n",
    "        labels (ndarray): The train set labels\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the list of classes and their ratios\n",
    "    \"\"\"\n",
    "    classes, counts = np.unique(labels, return_counts=True)\n",
    "    ratios = [counts[i] / len(labels) for i in range(len(classes))]\n",
    "    return classes, ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wpu-9m-vAhX_"
   },
   "source": [
    "### Dataset Class\n",
    "\n",
    "We encapsulate the train and test datasets by a Tabulardataset class which also normalizes the feature values. Further customization and data transformation can be done according to the needs of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3BWSyP6L9A4B"
   },
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    \"\"\"Tabular dataset\"\"\"\n",
    "\n",
    "    def __init__(self, features: np.ndarray, labels: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dset_name (string): Dataset name\n",
    "            dset_src (string): Dataset source file\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "        \"\"\"\n",
    "        self.features = torch.from_numpy(features)\n",
    "        self.features = torch.sigmoid(self.features)\n",
    "        self.labels = torch.from_numpy(labels)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "    def num_classes(self) -> int:\n",
    "        return len(torch.unique(self.labels))\n",
    "\n",
    "    def num_features(self) -> int:\n",
    "        return len(self.features[0])\n",
    "\n",
    "    def labels_dim(self) -> int:\n",
    "        return self.num_classes if self.num_classes() > 2 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_7aXSqof0hq"
   },
   "source": [
    "## Trainer\n",
    "\n",
    "The trainer class is in charge of training and evaluating the DP-CGAN model.\n",
    "\n",
    "1. ``train`` method performs the generator and discriminator training steps by providing the noise and labels as the inputs to the Generator. The Discriminator takes the samples from the training dataset to predict the fakeness of the generated samples. During the training, the spent privacy budget is watched over. Evaluation and checkpointing are done after a pre-determined number of iterations.\n",
    " \n",
    "2. Evaluation is performed in the following order:\n",
    "\n",
    "    a. Fixed tensors of noise and labels are fed into the Generator so that the model generates the synthetic data samples conditioned on the labels. The size of the generated dataset is determined by the ``synthetic_data_size`` parameter.\n",
    "\n",
    "    b. To evaluate the Generator's performance, we use the synthetic dataset to train an MLP classifier. The classifier is then tested on the test subset of the real dataset we split before. \n",
    "    \n",
    "    c. We report AUC (Area under the ROC curve) and AP (average precision score) as the evaluation metrics. The higher values of AUC on the real test dataset show a well-trained classifier, which is proof of a good training dataset. A good training dataset here is the synthetic dataset generated by the Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UbjPhriPgAhW"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Trainer:\n",
    "    \"\"\"A trainer for CGAN with differential privacy\"\"\"\n",
    "\n",
    "    generator: Generator\n",
    "    optimizerG: torch.optim\n",
    "    discriminator: Discriminator\n",
    "    optimizerD: torch.optim\n",
    "    criterion: torch.nn.modules.loss\n",
    "    #privacy_engine: PrivacyEngine\n",
    "    train_loader: DataLoader\n",
    "    test_dataset: TabularDataset\n",
    "    target_epsilon: float\n",
    "    target_delta: float\n",
    "    device: str\n",
    "    epochs: int\n",
    "    latent_dim: int\n",
    "    fixed_noise: torch.Tensor\n",
    "    fixed_labels: np.ndarray\n",
    "    exp_dir: str\n",
    "    eval_period: int\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.n_classes = self.test_dataset.num_classes()\n",
    "\n",
    "    def train(self) -> Tuple[list, list]:\n",
    "        \"\"\"Trains the CGAN model with differetial privacy\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing list of evaluation metrics: AUC and average precision\n",
    "        \"\"\"\n",
    "\n",
    "        iteration = 0\n",
    "        best_auc = 0\n",
    "        budget = True\n",
    "        mlp_aucs = []\n",
    "        mlp_aps = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            if not budget:\n",
    "                print(\n",
    "                    \"Privacy budget exceeded! Iteration = %d, ε = %.3f\"\n",
    "                    % (iteration, epsilon)\n",
    "                )\n",
    "                break\n",
    "\n",
    "            for _, data in enumerate(self.train_loader):\n",
    "\n",
    "                real_data = data[0].type(torch.FloatTensor).to(self.device)\n",
    "                real_labels = data[1].to(self.device)\n",
    "                batch_size = real_data.size(0)\n",
    "\n",
    "                label_fake = torch.full(\n",
    "                    (batch_size, 1), 0.0, device=self.device\n",
    "                )\n",
    "                label_true = torch.full(\n",
    "                    (batch_size, 1), 1.0, device=self.device\n",
    "                )\n",
    "\n",
    "                ######################\n",
    "                # (1) Update D network\n",
    "                ######################\n",
    "                self.optimizerD.zero_grad()\n",
    "\n",
    "                # train with fake data\n",
    "                noise = torch.randn(\n",
    "                    batch_size, self.latent_dim, device=self.device\n",
    "                )\n",
    "                gen_labels = torch.randint(\n",
    "                    0, self.n_classes, (batch_size,), device=self.device\n",
    "                )\n",
    "\n",
    "                fake = self.generator(noise, gen_labels)\n",
    "\n",
    "                output = self.discriminator(fake.detach(), gen_labels)\n",
    "                errD_fake = self.criterion(output, label_fake)\n",
    "                errD_fake.backward()\n",
    "                self.optimizerD.step()\n",
    "                self.optimizerD.zero_grad()\n",
    "\n",
    "                # train with real data\n",
    "                output = self.discriminator(real_data, real_labels)\n",
    "                errD_real = self.criterion(output, label_true)\n",
    "                errD_real.backward()\n",
    "                self.optimizerD.step()\n",
    "\n",
    "                errD = errD_real + errD_fake\n",
    "\n",
    "                ######################\n",
    "                # (2) Update G network\n",
    "                ######################\n",
    "                self.optimizerG.zero_grad()\n",
    "                self.optimizerD.zero_grad()\n",
    "\n",
    "                output_g = self.discriminator(fake, gen_labels)\n",
    "                errG = self.criterion(output_g, label_true)\n",
    "                errG.backward()\n",
    "\n",
    "                self.optimizerG.step()\n",
    "\n",
    "                #(\n",
    "                #    epsilon,\n",
    "                #    best_alpha,\n",
    "                #) = self.privacy_engine.accountant.get_privacy_spent(\n",
    "                #    delta=self.target_delta\n",
    "                #)\n",
    "\n",
    "                #if epsilon > self.target_epsilon:\n",
    "                #    budget = False\n",
    "                #    break\n",
    "\n",
    "                iteration = iteration + 1\n",
    "                if iteration % self.eval_period == 0:\n",
    "\n",
    "                    print(\n",
    "                        \"Iteration = %d, Loss_D = %.2f, Loss_G = %.2f\"\n",
    "                        % (iteration, errD.item(), errG.item())\n",
    "                    )\n",
    "                    #print(\n",
    "                    #    \"(ε = %.3f, δ = %.2f) for α = %.2f\"\n",
    "                    #    % (epsilon, self.target_delta, best_alpha)\n",
    "                    #)\n",
    "                    mlp_auc, mlp_ap = self._eval()\n",
    "                    mlp_aucs.append(mlp_auc)\n",
    "                    mlp_aps.append(mlp_ap)\n",
    "                    print(\"mlp_auc = %.3f, mlp_ap = %.3f\" % (mlp_auc, mlp_ap))\n",
    "                    if mlp_auc > best_auc:\n",
    "                        best_auc = mlp_auc\n",
    "                        print(\n",
    "                            f\"Checkpoint saved at iteration={iteration}\"#\", \n",
    "                            #eps={epsilon:.3f}\"\n",
    "                        )\n",
    "                        print(self.discriminator.__dict__)\n",
    "                        torch.save(\n",
    "                            {\n",
    "                                \"discriminator\": self.discriminator.state_dict(),\n",
    "                                \"generator\": self.generator.state_dict(),\n",
    "                                #\"accountant\": self.privacy_engine.accountant,\n",
    "                                \"optimizerG\": self.optimizerG.state_dict(),\n",
    "                                \"optimmizerD\": self.optimizerD.state_dict(),\n",
    "                            },\n",
    "                            f\"{self.exp_dir}/checkpoint_{iteration}.pth\"#_{epsilon:.3f}.pth\",\n",
    "                        )\n",
    "\n",
    "        return mlp_aucs, mlp_aps\n",
    "\n",
    "    def _eval(self) -> Tuple[float, float]:\n",
    "        \"\"\"Evaluates the model by applying mlp classifier\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the classifier AUC and average precision\n",
    "        \"\"\"\n",
    "        fake_features, fake_labels = self._generate_fake_data()\n",
    "        mlp = MLPClassifier(early_stopping=True).fit(\n",
    "            fake_features, fake_labels.flatten()\n",
    "        )\n",
    "        class_probs = mlp.predict_proba(self.test_dataset.features)\n",
    "\n",
    "        auc = metrics.roc_auc_score(\n",
    "            self.test_dataset.labels,\n",
    "            class_probs[:, 1],\n",
    "            average=\"weighted\",\n",
    "            multi_class=\"ovo\",\n",
    "        )\n",
    "\n",
    "        if self.n_classes > 2:\n",
    "            lb = LabelBinarizer()\n",
    "            lb.fit(self.test_dataset.labels)\n",
    "            y_test = lb.transform(self.test_dataset.labels)\n",
    "        else:\n",
    "            y_test = self.test_dataset.labels\n",
    "\n",
    "        ap = metrics.average_precision_score(y_test, class_probs[:, 1])\n",
    "        return auc, ap\n",
    "\n",
    "    def _generate_fake_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"generates fake dataset using the DP-CGAN generator\n",
    "\n",
    "        Returns:\n",
    "            A tuple of generted features and their corresponding labels\n",
    "        \"\"\"\n",
    "        fixed_labels = torch.from_numpy(self.fixed_labels).to(self.device)\n",
    "        fake_features = self.generator(self.fixed_noise, fixed_labels).detach()\n",
    "        fake_features = fake_features.cpu().numpy()\n",
    "        return fake_features, self.fixed_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt4o2e_demYI"
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Below are the arguments and hyperparameters used for training and evaluating DP-CGAN. These values can be changed according to your dataset and the configuration of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8FaXUemMaYp_"
   },
   "outputs": [],
   "source": [
    "dset_args = {\n",
    "    \"credit_fraud_src\": \"/ssd003/projects/aieng/public/SyntheticBootcampDatasets/credit_fraud/\",\n",
    "    \"credit_fraud_name\": \"credit_fraud\",\n",
    "    \"credit_fraud_dim\": 29,\n",
    "    \"adult_census_file\": \"/ssd003/projects/aieng/public/SyntheticBootcampDatasets/adult_census\",\n",
    "    \"adult_census_name\": \"adult_census\",\n",
    "    \"adult_census_dim\": 11,\n",
    "    \"cervical_cancer_file\": \"/ssd003/projects/aieng/public/SyntheticBootcampDatasets/cervical_cancer\",\n",
    "    \"cervical_cancer_name\": \"cervical_cancer\",\n",
    "    \"cervical_cancer_dim\": 33,\n",
    "    \"UCI_ISOLET_file\": \"/ssd003/projects/aieng/public/SyntheticBootcampDatasets/UCI_ISOLET\",\n",
    "    \"UCI_ISOLET_name\": \"UCI_ISOLET\",\n",
    "    \"UCI_ISOLET_dim\": 617,\n",
    "}\n",
    "ARGS = {\n",
    "    \"seed\": 42069,\n",
    "    \"secure_rng\": False,\n",
    "    # Enable Secure RNG to have trustworthy privacy guarantees. Comes at a performance cost\n",
    "    \"epsilon\": 0.55,\n",
    "    # Target epsilon\n",
    "    \"max_per_sample_grad_norm\": 1.0,\n",
    "    # Clip per-sample gradients to this norm\n",
    "    \"delta\": 1e-5,\n",
    "    # Target delta\n",
    "    \"latent_dim\": 100,\n",
    "    # Size of the latent z vector\n",
    "    \"ngf\": 128,\n",
    "    # Number of features in the generator layers\n",
    "    \"ndf\": 128,\n",
    "    # Number of features in the discriminator layers\n",
    "    \"epochs\": 5,\n",
    "    # Number of epochs to spend the privacy budget for\n",
    "    \"lr\": 0.0002,\n",
    "    # Learning rate\n",
    "    \"beta1\": 0.5,\n",
    "    # Beta1 for adam\n",
    "    \"beta2\": 0.999,\n",
    "    # Beta2 for adam\n",
    "    \"eval_period\": 100,\n",
    "    # Evaluation and checkpointing interval\n",
    "    \"dset_src\": dset_args[\"credit_fraud_src\"],\n",
    "    # Dataset directory\n",
    "    \"dset_name\": dset_args[\"credit_fraud_name\"],\n",
    "    # Dataset name\n",
    "    \"workers\": 2,\n",
    "    # Number of data loading workers\n",
    "    \"batch_size\": 128,\n",
    "    # Training batch size\n",
    "    \"split_ratio\": 0.2,\n",
    "    # Test ratio for splitting the dataset\n",
    "    \"synth_data_size\": 250000,\n",
    "    # Size of synthetic dataset for evaluation\n",
    "    \"checkpoint\": \"\",\n",
    "    # Path to checkpoint file\n",
    "    \"exp_dir\": \"./default_exp\"\n",
    "    # Experiment directory\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtmbGsNOgJxN"
   },
   "source": [
    "## Main\n",
    "\n",
    "``main`` script instantiates the modules and privacy engine, calls the ``train`` method, and terminates by saving the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iVUqsjsigQVV"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    os.makedirs(ARGS[\"exp_dir\"], exist_ok=True)\n",
    "\n",
    "    torch.manual_seed(ARGS[\"seed\"])\n",
    "    rng = np.random.default_rng(ARGS[\"seed\"])\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    (train_features, train_labels, test_features, test_labels) = split_dataset(\n",
    "        ARGS[\"split_ratio\"],\n",
    "        ARGS[\"dset_name\"],\n",
    "        ARGS[\"dset_src\"],\n",
    "    )\n",
    "\n",
    "    train_dataset = TabularDataset(train_features, train_labels)\n",
    "    test_dataset = TabularDataset(test_features, test_labels)\n",
    "\n",
    "    features_dim = train_dataset.num_features()\n",
    "    labels_dim = train_dataset.labels_dim()\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        num_workers=ARGS[\"workers\"],\n",
    "        batch_size=ARGS[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    generator = Generator(\n",
    "        latent_dim=ARGS[\"latent_dim\"],\n",
    "        ngf=ARGS[\"ngf\"],\n",
    "        features_dim=features_dim,\n",
    "        labels_dim=labels_dim,\n",
    "    )\n",
    "    generator = generator.to(device)\n",
    "    generator.apply(init_weights)\n",
    "\n",
    "    optimizerG = optim.Adam(\n",
    "        generator.parameters(),\n",
    "        lr=ARGS[\"lr\"],\n",
    "        betas=(ARGS[\"beta1\"], ARGS[\"beta2\"]),\n",
    "    )\n",
    "\n",
    "    discriminator = Discriminator(\n",
    "        ndf=ARGS[\"ndf\"], features_dim=features_dim, labels_dim=labels_dim\n",
    "    )\n",
    "    discriminator = discriminator.to(device)\n",
    "    discriminator.apply(init_weights)\n",
    "\n",
    "    optimizerD = optim.Adam(\n",
    "        discriminator.parameters(),\n",
    "        lr=ARGS[\"lr\"],\n",
    "        betas=(ARGS[\"beta1\"], ARGS[\"beta2\"]),\n",
    "    )\n",
    "\n",
    "    #privacy_engine = PrivacyEngine(secure_mode=ARGS[\"secure_rng\"])\n",
    "\n",
    "    if ARGS[\"checkpoint\"] != \"\":\n",
    "        checkpoint = torch.load(ARGS[\"checkpoint\"])\n",
    "        generator.load_state_dict(checkpoint[\"generator\"])\n",
    "        discriminator.load_state_dict(checkpoint[\"discriminator\"])\n",
    "        optimizerG.load_state_dict(checkpoint[\"optimizerG\"])\n",
    "        optimizerD.load_state_dict(checkpoint[\"optimmizerD\"])\n",
    "        #privacy_engine.accountant = checkpoint[\"accountant\"]\n",
    "\n",
    "        print(f'checkpoint loaded from {ARGS[\"checkpoint\"]}')\n",
    "\n",
    "    # Opacus adds privacy-related responsibilites to the main PyTorch training objects:\n",
    "    # model, optimizer, and the data loader.\n",
    "    #(\n",
    "    #    discriminator,\n",
    "    #    optimizerD,\n",
    "    #    train_loader,\n",
    "    #) = privacy_engine.make_private_with_epsilon(\n",
    "    #    module=discriminator,\n",
    "    #    optimizer=optimizerD,\n",
    "    #    data_loader=train_loader,\n",
    "    #    max_grad_norm=ARGS[\"max_per_sample_grad_norm\"],\n",
    "    #    target_epsilon=ARGS[\"epsilon\"],\n",
    "    #    target_delta=ARGS[\"delta\"],\n",
    "    #    epochs=ARGS[\"epochs\"],\n",
    "    #)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    fakedata_size = min(train_dataset.__len__(), ARGS[\"synth_data_size\"])\n",
    "    fixed_noise = torch.randn(fakedata_size, ARGS[\"latent_dim\"], device=device)\n",
    "    classes, ratios = class_ratios(train_labels)\n",
    "    fixed_labels = rng.choice(classes, size=fakedata_size, p=ratios)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        generator=generator,\n",
    "        optimizerG=optimizerG,\n",
    "        discriminator=discriminator,\n",
    "        optimizerD=optimizerD,\n",
    "        criterion=criterion,\n",
    "        #privacy_engine=privacy_engine,\n",
    "        train_loader=train_loader,\n",
    "        test_dataset=test_dataset,\n",
    "        target_epsilon=ARGS[\"epsilon\"],\n",
    "        target_delta=ARGS[\"delta\"],\n",
    "        device=device,\n",
    "        epochs=ARGS[\"epochs\"],\n",
    "        latent_dim=ARGS[\"latent_dim\"],\n",
    "        fixed_noise=fixed_noise,\n",
    "        fixed_labels=fixed_labels,\n",
    "        exp_dir=ARGS[\"exp_dir\"],\n",
    "        eval_period=ARGS[\"eval_period\"],\n",
    "    )\n",
    "\n",
    "    mlp_aucs, mlp_aps = trainer.train()\n",
    "\n",
    "    iters = np.arange(\n",
    "        ARGS[\"eval_period\"],\n",
    "        (len(mlp_aucs) + 1) * ARGS[\"eval_period\"],\n",
    "        ARGS[\"eval_period\"],\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"iter\": iters,\n",
    "            \"mlp_auc\": np.array(mlp_aucs),\n",
    "            \"mlp_ap\": np.array(mlp_aps),\n",
    "        }\n",
    "    )\n",
    "    df.plot(\n",
    "        x=\"iter\",\n",
    "        y=[\"mlp_auc\", \"mlp_ap\"],\n",
    "        kind=\"line\",\n",
    "        xticks=iters // ARGS[\"eval_period\"],\n",
    "        xlabel=f'iters/{ARGS[\"eval_period\"]}',\n",
    "    )\n",
    "    plt.savefig(f'{ARGS[\"exp_dir\"]}/mlp_auc.png')\n",
    "    df.to_csv(f'{ARGS[\"exp_dir\"]}/mlp_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 100, Loss_D = 1.12, Loss_G = 0.59\n",
      "mlp_auc = 0.854, mlp_ap = 0.119\n",
      "Checkpoint saved at iteration=100\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('model', Sequential(\n",
      "  (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      "))]), 'labels_dim': 1, 'features_dim': 29, 'ndf': 128}\n",
      "Iteration = 200, Loss_D = 1.27, Loss_G = 0.79\n",
      "mlp_auc = 0.908, mlp_ap = 0.460\n",
      "Checkpoint saved at iteration=200\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('model', Sequential(\n",
      "  (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      "))]), 'labels_dim': 1, 'features_dim': 29, 'ndf': 128}\n",
      "Iteration = 300, Loss_D = 1.16, Loss_G = 1.09\n",
      "mlp_auc = 0.859, mlp_ap = 0.495\n",
      "Iteration = 400, Loss_D = 1.13, Loss_G = 1.18\n",
      "mlp_auc = 0.880, mlp_ap = 0.454\n",
      "Iteration = 500, Loss_D = 1.08, Loss_G = 1.21\n",
      "mlp_auc = 0.810, mlp_ap = 0.077\n",
      "Iteration = 600, Loss_D = 1.02, Loss_G = 1.24\n",
      "mlp_auc = 0.913, mlp_ap = 0.424\n",
      "Checkpoint saved at iteration=600\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('model', Sequential(\n",
      "  (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      "))]), 'labels_dim': 1, 'features_dim': 29, 'ndf': 128}\n",
      "Iteration = 700, Loss_D = 1.05, Loss_G = 1.06\n",
      "mlp_auc = 0.879, mlp_ap = 0.188\n",
      "Iteration = 800, Loss_D = 0.96, Loss_G = 1.33\n",
      "mlp_auc = 0.907, mlp_ap = 0.116\n",
      "Iteration = 900, Loss_D = 0.98, Loss_G = 1.35\n",
      "mlp_auc = 0.894, mlp_ap = 0.265\n",
      "Iteration = 1000, Loss_D = 0.91, Loss_G = 1.53\n",
      "mlp_auc = 0.887, mlp_ap = 0.113\n",
      "Iteration = 1100, Loss_D = 0.95, Loss_G = 1.56\n",
      "mlp_auc = 0.915, mlp_ap = 0.204\n",
      "Checkpoint saved at iteration=1100\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('model', Sequential(\n",
      "  (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      "))]), 'labels_dim': 1, 'features_dim': 29, 'ndf': 128}\n",
      "Iteration = 1200, Loss_D = 0.92, Loss_G = 1.78\n",
      "mlp_auc = 0.731, mlp_ap = 0.020\n",
      "Iteration = 1300, Loss_D = 0.98, Loss_G = 1.69\n",
      "mlp_auc = 0.288, mlp_ap = 0.001\n",
      "Iteration = 1400, Loss_D = 0.99, Loss_G = 1.96\n",
      "mlp_auc = 0.612, mlp_ap = 0.004\n",
      "Iteration = 1500, Loss_D = 0.92, Loss_G = 2.02\n",
      "mlp_auc = 0.445, mlp_ap = 0.001\n",
      "Iteration = 1600, Loss_D = 0.92, Loss_G = 2.16\n",
      "mlp_auc = 0.414, mlp_ap = 0.001\n",
      "Iteration = 1700, Loss_D = 0.94, Loss_G = 2.16\n",
      "mlp_auc = 0.286, mlp_ap = 0.001\n",
      "Iteration = 1800, Loss_D = 1.00, Loss_G = 2.17\n",
      "mlp_auc = 0.221, mlp_ap = 0.001\n",
      "Iteration = 1900, Loss_D = 1.03, Loss_G = 2.07\n",
      "mlp_auc = 0.249, mlp_ap = 0.001\n",
      "Iteration = 2000, Loss_D = 1.01, Loss_G = 2.15\n",
      "mlp_auc = 0.289, mlp_ap = 0.001\n",
      "Iteration = 2100, Loss_D = 0.96, Loss_G = 2.45\n",
      "mlp_auc = 0.425, mlp_ap = 0.001\n",
      "Iteration = 2200, Loss_D = 0.91, Loss_G = 2.69\n",
      "mlp_auc = 0.460, mlp_ap = 0.002\n",
      "Iteration = 2300, Loss_D = 0.88, Loss_G = 2.85\n",
      "mlp_auc = 0.699, mlp_ap = 0.008\n",
      "Iteration = 2400, Loss_D = 0.95, Loss_G = 2.74\n",
      "mlp_auc = 0.753, mlp_ap = 0.016\n",
      "Iteration = 2500, Loss_D = 0.90, Loss_G = 2.96\n",
      "mlp_auc = 0.766, mlp_ap = 0.008\n",
      "Iteration = 2600, Loss_D = 0.94, Loss_G = 2.77\n",
      "mlp_auc = 0.805, mlp_ap = 0.009\n",
      "Iteration = 2700, Loss_D = 1.04, Loss_G = 2.42\n",
      "mlp_auc = 0.812, mlp_ap = 0.009\n",
      "Iteration = 2800, Loss_D = 0.93, Loss_G = 2.95\n",
      "mlp_auc = 0.723, mlp_ap = 0.004\n",
      "Iteration = 2900, Loss_D = 1.00, Loss_G = 2.67\n",
      "mlp_auc = 0.815, mlp_ap = 0.019\n",
      "Iteration = 3000, Loss_D = 0.97, Loss_G = 2.82\n",
      "mlp_auc = 0.633, mlp_ap = 0.003\n",
      "Iteration = 3100, Loss_D = 1.13, Loss_G = 2.31\n",
      "mlp_auc = 0.680, mlp_ap = 0.003\n",
      "Iteration = 3200, Loss_D = 1.01, Loss_G = 2.73\n",
      "mlp_auc = 0.680, mlp_ap = 0.004\n",
      "Iteration = 3300, Loss_D = 0.93, Loss_G = 3.07\n",
      "mlp_auc = 0.783, mlp_ap = 0.006\n",
      "Iteration = 3400, Loss_D = 1.06, Loss_G = 2.56\n",
      "mlp_auc = 0.685, mlp_ap = 0.005\n",
      "Iteration = 3500, Loss_D = 1.03, Loss_G = 2.67\n",
      "mlp_auc = 0.815, mlp_ap = 0.024\n",
      "Iteration = 3600, Loss_D = 1.05, Loss_G = 2.54\n",
      "mlp_auc = 0.830, mlp_ap = 0.123\n",
      "Iteration = 3700, Loss_D = 1.02, Loss_G = 2.65\n",
      "mlp_auc = 0.841, mlp_ap = 0.233\n",
      "Iteration = 3800, Loss_D = 0.96, Loss_G = 3.18\n",
      "mlp_auc = 0.822, mlp_ap = 0.324\n",
      "Iteration = 3900, Loss_D = 1.10, Loss_G = 2.38\n",
      "mlp_auc = 0.850, mlp_ap = 0.500\n",
      "Iteration = 4000, Loss_D = 1.06, Loss_G = 2.51\n",
      "mlp_auc = 0.828, mlp_ap = 0.509\n",
      "Iteration = 4100, Loss_D = 0.94, Loss_G = 2.97\n",
      "mlp_auc = 0.854, mlp_ap = 0.400\n",
      "Iteration = 4200, Loss_D = 1.12, Loss_G = 2.83\n",
      "mlp_auc = 0.812, mlp_ap = 0.232\n",
      "Iteration = 4300, Loss_D = 1.02, Loss_G = 2.72\n",
      "mlp_auc = 0.798, mlp_ap = 0.225\n",
      "Iteration = 4400, Loss_D = 1.00, Loss_G = 2.75\n",
      "mlp_auc = 0.831, mlp_ap = 0.077\n",
      "Iteration = 4500, Loss_D = 0.95, Loss_G = 3.16\n",
      "mlp_auc = 0.777, mlp_ap = 0.024\n",
      "Iteration = 4600, Loss_D = 0.94, Loss_G = 3.00\n",
      "mlp_auc = 0.849, mlp_ap = 0.048\n",
      "Iteration = 4700, Loss_D = 1.04, Loss_G = 2.65\n",
      "mlp_auc = 0.748, mlp_ap = 0.012\n",
      "Iteration = 4800, Loss_D = 0.87, Loss_G = 3.41\n",
      "mlp_auc = 0.779, mlp_ap = 0.032\n",
      "Iteration = 4900, Loss_D = 1.06, Loss_G = 2.76\n",
      "mlp_auc = 0.898, mlp_ap = 0.131\n",
      "Iteration = 5000, Loss_D = 0.91, Loss_G = 3.16\n",
      "mlp_auc = 0.916, mlp_ap = 0.254\n",
      "Checkpoint saved at iteration=5000\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('model', Sequential(\n",
      "  (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      "))]), 'labels_dim': 1, 'features_dim': 29, 'ndf': 128}\n",
      "Iteration = 5100, Loss_D = 0.96, Loss_G = 3.16\n",
      "mlp_auc = 0.914, mlp_ap = 0.200\n",
      "Iteration = 5200, Loss_D = 0.87, Loss_G = 3.37\n",
      "mlp_auc = 0.877, mlp_ap = 0.517\n",
      "Iteration = 5300, Loss_D = 0.99, Loss_G = 2.91\n",
      "mlp_auc = 0.917, mlp_ap = 0.562\n",
      "Checkpoint saved at iteration=5300\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('model', Sequential(\n",
      "  (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      "))]), 'labels_dim': 1, 'features_dim': 29, 'ndf': 128}\n",
      "Iteration = 5400, Loss_D = 0.94, Loss_G = 3.16\n",
      "mlp_auc = 0.905, mlp_ap = 0.607\n",
      "Iteration = 5500, Loss_D = 1.03, Loss_G = 2.72\n",
      "mlp_auc = 0.882, mlp_ap = 0.509\n",
      "Iteration = 5600, Loss_D = 0.93, Loss_G = 3.20\n",
      "mlp_auc = 0.878, mlp_ap = 0.579\n",
      "Iteration = 5700, Loss_D = 0.95, Loss_G = 3.03\n",
      "mlp_auc = 0.905, mlp_ap = 0.568\n",
      "Iteration = 5800, Loss_D = 0.95, Loss_G = 3.24\n",
      "mlp_auc = 0.876, mlp_ap = 0.550\n",
      "Iteration = 5900, Loss_D = 1.01, Loss_G = 2.85\n",
      "mlp_auc = 0.907, mlp_ap = 0.595\n",
      "Iteration = 6000, Loss_D = 1.08, Loss_G = 2.71\n",
      "mlp_auc = 0.857, mlp_ap = 0.539\n",
      "Iteration = 6100, Loss_D = 0.98, Loss_G = 3.06\n",
      "mlp_auc = 0.944, mlp_ap = 0.629\n",
      "Checkpoint saved at iteration=6100\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('model', Sequential(\n",
      "  (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      "))]), 'labels_dim': 1, 'features_dim': 29, 'ndf': 128}\n",
      "Iteration = 6200, Loss_D = 0.97, Loss_G = 3.13\n",
      "mlp_auc = 0.879, mlp_ap = 0.577\n",
      "Iteration = 6300, Loss_D = 0.92, Loss_G = 3.28\n",
      "mlp_auc = 0.925, mlp_ap = 0.596\n",
      "Iteration = 6400, Loss_D = 1.02, Loss_G = 2.90\n",
      "mlp_auc = 0.910, mlp_ap = 0.604\n",
      "Iteration = 6500, Loss_D = 0.92, Loss_G = 3.17\n",
      "mlp_auc = 0.909, mlp_ap = 0.465\n",
      "Iteration = 6600, Loss_D = 0.89, Loss_G = 3.40\n",
      "mlp_auc = 0.912, mlp_ap = 0.508\n",
      "Iteration = 6700, Loss_D = 0.95, Loss_G = 3.12\n",
      "mlp_auc = 0.912, mlp_ap = 0.327\n",
      "Iteration = 6800, Loss_D = 0.92, Loss_G = 3.24\n",
      "mlp_auc = 0.875, mlp_ap = 0.540\n",
      "Iteration = 6900, Loss_D = 0.92, Loss_G = 3.30\n",
      "mlp_auc = 0.901, mlp_ap = 0.532\n",
      "Iteration = 7000, Loss_D = 1.10, Loss_G = 2.78\n",
      "mlp_auc = 0.842, mlp_ap = 0.496\n",
      "Iteration = 7100, Loss_D = 0.92, Loss_G = 3.16\n",
      "mlp_auc = 0.888, mlp_ap = 0.517\n",
      "Iteration = 7200, Loss_D = 1.05, Loss_G = 2.58\n",
      "mlp_auc = 0.873, mlp_ap = 0.467\n",
      "Iteration = 7300, Loss_D = 0.94, Loss_G = 3.23\n",
      "mlp_auc = 0.910, mlp_ap = 0.535\n",
      "Iteration = 7400, Loss_D = 0.90, Loss_G = 3.67\n",
      "mlp_auc = 0.908, mlp_ap = 0.553\n",
      "Iteration = 7500, Loss_D = 0.85, Loss_G = 3.38\n",
      "mlp_auc = 0.881, mlp_ap = 0.546\n",
      "Iteration = 7600, Loss_D = 0.92, Loss_G = 3.22\n",
      "mlp_auc = 0.883, mlp_ap = 0.274\n",
      "Iteration = 7700, Loss_D = 0.89, Loss_G = 3.14\n",
      "mlp_auc = 0.924, mlp_ap = 0.637\n",
      "Iteration = 7800, Loss_D = 0.99, Loss_G = 3.13\n",
      "mlp_auc = 0.928, mlp_ap = 0.614\n",
      "Iteration = 7900, Loss_D = 0.97, Loss_G = 3.09\n",
      "mlp_auc = 0.925, mlp_ap = 0.627\n",
      "Iteration = 8000, Loss_D = 0.97, Loss_G = 2.90\n",
      "mlp_auc = 0.924, mlp_ap = 0.633\n",
      "Iteration = 8100, Loss_D = 0.85, Loss_G = 2.83\n",
      "mlp_auc = 0.892, mlp_ap = 0.599\n",
      "Iteration = 8200, Loss_D = 0.89, Loss_G = 3.16\n",
      "mlp_auc = 0.906, mlp_ap = 0.633\n",
      "Iteration = 8300, Loss_D = 0.97, Loss_G = 3.31\n",
      "mlp_auc = 0.915, mlp_ap = 0.633\n",
      "Iteration = 8400, Loss_D = 1.00, Loss_G = 3.01\n",
      "mlp_auc = 0.929, mlp_ap = 0.486\n",
      "Iteration = 8500, Loss_D = 0.91, Loss_G = 3.36\n",
      "mlp_auc = 0.896, mlp_ap = 0.627\n",
      "Iteration = 8600, Loss_D = 1.01, Loss_G = 2.74\n",
      "mlp_auc = 0.888, mlp_ap = 0.528\n",
      "Iteration = 8700, Loss_D = 1.07, Loss_G = 2.91\n",
      "mlp_auc = 0.945, mlp_ap = 0.646\n",
      "Checkpoint saved at iteration=8700\n",
      "{'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict([('model', Sequential(\n",
      "  (0): Linear(in_features=30, out_features=128, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      "))]), 'labels_dim': 1, 'features_dim': 29, 'ndf': 128}\n",
      "Iteration = 8800, Loss_D = 1.03, Loss_G = 2.84\n",
      "mlp_auc = 0.850, mlp_ap = 0.613\n",
      "Iteration = 8900, Loss_D = 0.95, Loss_G = 3.25\n",
      "mlp_auc = 0.894, mlp_ap = 0.616\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DP-CGAN_Notebook.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "SyntheticData",
   "language": "python",
   "name": "synthetic_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
